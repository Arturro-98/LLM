{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPn8vUL+TULKUrPkpJ8ohoO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arturro-98/LLM/blob/main/RAG/LangChain_Multiple_doc_Chromadb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Multiple documents retrieval using Chromadb and OpenAI\n",
        "\n",
        "Chroma DB is an open-source embedding database (also known as a vector store) that makes it easy to build LLM apps by storing and retrieving embeddings and their metadata, as well as documents and queries. It’s designed to provide efficient, scalable, and flexible ways to store and search embeddings. Chroma DB enhances the overall performance and scalability of LLM applications by providing a robust backend for storing and querying vectorized data.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Langchain dataloaders:**\n",
        "\n",
        "\n",
        "https://docs.kanaries.net/topics/LangChain/langchain-document-loader\n",
        "\n",
        "https://medium.com/@varsha.rainer/document-loaders-in-langchain-7c2db9851123"
      ],
      "metadata": {
        "id": "sd5_Z-775lIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy==3.7.4 weasel==0.3.4\n",
        "!pip install typer==0.9.0\n",
        "\n",
        "!pip -q install langchain openai tiktoken chromadb\n",
        "!pip install -U langchain-openai\n",
        "\n",
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42h8qb_iyvik",
        "outputId": "32c50438-c9f0-4217-99f9-8d8a42600b9c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy==3.7.4 in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: weasel==0.3.4 in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (2.0.10)\n",
            "Collecting typer<0.10.0,>=0.3.0 (from spacy==3.7.4)\n",
            "  Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (1.25.2)\n",
            "Requirement already satisfied: confection<0.2.0,>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from weasel==0.3.4) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel==0.3.4) (0.16.0)\n",
            "Requirement already satisfied: typing_extensions>4 in /usr/local/lib/python3.10/dist-packages (from cloudpathlib<0.17.0,>=0.7.0->weasel==0.3.4) (4.11.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.7.4) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy==3.7.4) (0.7.11)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy==3.7.4) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.7.4) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.7.4) (1.1.1)\n",
            "Installing collected packages: typer\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.12.3\n",
            "    Uninstalling typer-0.12.3:\n",
            "      Successfully uninstalled typer-0.12.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastapi-cli 0.0.4 requires typer>=0.12.3, but you have typer 0.9.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typer-0.9.4\n",
            "Collecting typer==0.9.0\n",
            "  Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer==0.9.0) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from typer==0.9.0) (4.11.0)\n",
            "Installing collected packages: typer\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastapi-cli 0.0.4 requires typer>=0.12.3, but you have typer 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typer-0.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.2.1)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.30.3)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (0.1.63)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (2.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain-openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.46->langchain-openai) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.7)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.6)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.1)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.63)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (2.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (2.18.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "#from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings # To use embeddings from OpenAI\n",
        "from langchain_openai import ChatOpenAI # To use LLM from OpenAI"
      ],
      "metadata": {
        "id": "l3Fq1XbGGqx0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "# This function takes one argument of type dict and for result key, it will wrap the value, makes it easier to read. Written because answer is a long sting that was printed in one line.\n",
        "def response_wrap(resp):\n",
        "\n",
        "    for key, value in resp.items():\n",
        "        if key == 'result':\n",
        "            print(f\"{key}:\")\n",
        "            print(\"\\n\".join(textwrap.wrap(value, width=80)))\n",
        "\n",
        "        elif key == 'source_documents':\n",
        "            print('\\nSources:')\n",
        "            for doc in value:\n",
        "                if 'source' in doc.metadata:\n",
        "                    print(doc.metadata['source'])\n",
        "        else:\n",
        "            print(f\"{key}: {value}\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "U_D6hTbKQfol"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Mounting to gdrive** to get stored PDF files and copy them into Colab workspace (speed up fetching data process)\n",
        "\n",
        "**2. Loading Key (OpenAI) stored in a file in gdrive**"
      ],
      "metadata": {
        "id": "nxQ8heI5znjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connecting to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWlU7OeUyOIW",
        "outputId": "dfe75a8f-cbe5-46cd-a63c-673852c4e23d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Key (OpenAI) stored in a file in gdrive**"
      ],
      "metadata": {
        "id": "5A9sPQLkyZlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/Colab_Notebooks/LLM-RAG/')\n",
        "from get_access import get_func\n",
        "key_and_token = get_func() # Function returns the list with OpenAI key[0] & HuggingFace token[1]"
      ],
      "metadata": {
        "id": "6tsUaAcbybyt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.youtube.com/watch?v=3yPBVii7Ct0&t=344s\n",
        "\n",
        "import os\n",
        "key = key_and_token[0] # Returned OpenAI key string from a function\n",
        "os.environ[\"OPENAI_API_KEY\"] = key"
      ],
      "metadata": {
        "id": "qLMHsL7oIvZU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_folder_path = f'{root_dir}Colab_Notebooks/LLM-RAG//Data/' # PDF files on gdrive\n",
        "os.listdir(pdf_folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIw1eCtFzRsA",
        "outputId": "790d6be5-6448-4013-ccce-12d09ef5d909"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Neuroscience-Psychology-and-Conflict-Management-1710202873._print.pdf',\n",
              " 'Psychology-of-Human-Relations-1695056929._print.pdf',\n",
              " 'Fundamentals-of-Psychological-Disorders.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/Data') # Making 'Data' folder in Colab workspace to copy all documents"
      ],
      "metadata": {
        "id": "FFHcbZ-yzX_R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Copy all data from Gdrive into created Data folder in Colab'''\n",
        "\n",
        "import shutil\n",
        "\n",
        "data_dir = '/content/Data/'\n",
        "\n",
        "files = os.listdir(pdf_folder_path)\n",
        "for file in files:\n",
        "    shutil.copy(os.path.join(pdf_folder_path, file), data_dir) # Copying all files into Colab workspace to speed up fetching data process"
      ],
      "metadata": {
        "id": "bSET3wX6zbQp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf # Required for .load()\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCIEvNZ7KkDj",
        "outputId": "4d1711a0-2ce2-4bb6-c266-4e757516a3ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/290.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading multiple PDF documents - dataloader**\n"
      ],
      "metadata": {
        "id": "XvRrvCY6g0O0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/Data/'\n",
        "loader = PyPDFDirectoryLoader(data_path)\n",
        "\n",
        "#Can try UnstructuredPDFLoader from from langchain.document_loaders import UnstructuredPDFLoader"
      ],
      "metadata": {
        "id": "yCrNqPuxKVsJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "lbeJZTdpKZet"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the text into\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvZ9hlrmNapx",
        "outputId": "edfee330-1063-4aa9-f126-9ecd8e803166"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3308"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[13] # Chunk of a document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNGnnPyINgY7",
        "outputId": "f74017ee-08a6-4360-b37c-159604a3ecbd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='purposes only; and\\nproduce, reproduce, and Share Adapted Material for NonCommercial purposes only.B.\\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations2.\\napply to Your use, this Public License does not apply, and You do not need to comply with its\\nterms and conditions.\\nTerm. The term of this Public License is specified in Section 6(a). 3.\\nMedia and formats; technical modifications allowed. The Licensor authorizes You to4.\\nexercise the Licensed Rights in all media and formats whether now known or hereafter\\ncreated, and to make technical modifications necessary to do so. The Licensor waives and/or\\nagrees not to assert any right or authority to forbid You from making technical\\nmodifications necessary to exercise the Licensed Rights, including technical modifications\\nnecessary to circumvent Effective Technological Measures. For purposes of this Public\\nLicense, simply making modifications authorized by this Section 2(a)(4)  never produces', metadata={'source': '/content/Data/Fundamentals-of-Psychological-Disorders.pdf', 'page': 7})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Data Base\n",
        "\n",
        "Store PDF texts as Vector Store in folder db\n",
        "\n",
        "While LangChain provides the framework for building and deploying AI applications, Chroma DB provides the database for storing and retrieving the vector embeddings that these applications use."
      ],
      "metadata": {
        "id": "nvLjSUKk2qf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed and store the texts from PDFs\n",
        "# Store the embeddings on disk in folder name from persist_directory\n",
        "persist_directory = 'db'\n",
        "\n",
        "# Initialize embeddings\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=texts,\n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=persist_directory)"
      ],
      "metadata": {
        "id": "DMfsUnOiNzBP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading persisted database from disk, and use it as normal.\n",
        "vectordb = Chroma(persist_directory=persist_directory,\n",
        "                  embedding_function=embedding)"
      ],
      "metadata": {
        "id": "hbXEal04OIvp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retriever"
      ],
      "metadata": {
        "id": "Sr1jv2KOjmTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "2ZUYnRWnOLig"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.invoke(\"Tell me something about Interpersonal communication?\")"
      ],
      "metadata": {
        "id": "DaNU29CS9qvL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs) # By default 4 relevant documents are return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz-AlW49OYmK",
        "outputId": "1a40cf87-fa6c-4f6d-b112-c332aab1695f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2}) # Setting to retreive 2 top most relevant documents"
      ],
      "metadata": {
        "id": "Vc4PKU7UObzb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.search_type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "38H49-_COdpX",
        "outputId": "429a4e59-9651-46f6-f864-b097201fb561"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'similarity'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.search_kwargs # 2 (documents) as it was set above"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtt-s8VFOhip",
        "outputId": "0d7bce30-412f-4829-fb6c-846cb5895b13"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'k': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List of openAI models\n",
        "\n",
        "Using the json module to print it in a more readable format"
      ],
      "metadata": {
        "id": "tkEKqqsZp0LP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.getenv('OPENAI_API_KEY')\n",
        ")\n",
        "\n",
        "models = client.models.list()\n",
        "\n",
        "# Extract the data from the SyncPage[Model] object\n",
        "model_list = []\n",
        "for model in models.data:\n",
        "    model_dict = {\n",
        "        'id': model.id,\n",
        "        'created': model.created,\n",
        "        'object': model.object,\n",
        "        'owned_by': model.owned_by\n",
        "    }\n",
        "    model_list.append(model_dict)\n",
        "\n",
        "# Pretty print the models list\n",
        "print(json.dumps(model_list, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI3NaB4np1OD",
        "outputId": "8815446e-ebf1-40ca-ddeb-4e387fb6dd6d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"id\": \"dall-e-3\",\n",
            "    \"created\": 1698785189,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-4-1106-preview\",\n",
            "    \"created\": 1698957206,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"whisper-1\",\n",
            "    \"created\": 1677532384,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"openai-internal\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"davinci-002\",\n",
            "    \"created\": 1692634301,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-4-turbo-preview\",\n",
            "    \"created\": 1706037777,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-4-0125-preview\",\n",
            "    \"created\": 1706037612,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"babbage-002\",\n",
            "    \"created\": 1692634615,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"dall-e-2\",\n",
            "    \"created\": 1698798177,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-3.5-turbo-16k\",\n",
            "    \"created\": 1683758102,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"openai-internal\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"tts-1-hd-1106\",\n",
            "    \"created\": 1699053533,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"tts-1-hd\",\n",
            "    \"created\": 1699046015,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-4\",\n",
            "    \"created\": 1687882411,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"openai\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-4-0613\",\n",
            "    \"created\": 1686588896,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"openai\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-3.5-turbo-1106\",\n",
            "    \"created\": 1698959748,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-3.5-turbo-instruct-0914\",\n",
            "    \"created\": 1694122472,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-3.5-turbo-instruct\",\n",
            "    \"created\": 1692901427,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"tts-1\",\n",
            "    \"created\": 1681940951,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"openai-internal\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-3.5-turbo-0301\",\n",
            "    \"created\": 1677649963,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"openai\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-3.5-turbo-0125\",\n",
            "    \"created\": 1706048358,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-3.5-turbo\",\n",
            "    \"created\": 1677610602,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"openai\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"tts-1-1106\",\n",
            "    \"created\": 1699053241,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"text-embedding-3-large\",\n",
            "    \"created\": 1705953180,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-4-turbo-2024-04-09\",\n",
            "    \"created\": 1712601677,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-4-turbo\",\n",
            "    \"created\": 1712361441,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"text-embedding-3-small\",\n",
            "    \"created\": 1705948997,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-3.5-turbo-0613\",\n",
            "    \"created\": 1686587434,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"openai\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"text-embedding-ada-002\",\n",
            "    \"created\": 1671217299,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"openai-internal\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-4-1106-vision-preview\",\n",
            "    \"created\": 1711473033,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-4-vision-preview\",\n",
            "    \"created\": 1698894917,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-3.5-turbo-16k-0613\",\n",
            "    \"created\": 1685474247,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"openai\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-4o\",\n",
            "    \"created\": 1715367049,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"gpt-4o-2024-05-13\",\n",
            "    \"created\": 1715368132,\n",
            "    \"object\": \"model\",\n",
            "    \"owned_by\": \"system\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain"
      ],
      "metadata": {
        "id": "cdShzslGr_Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the turbo LLM\n",
        "model = ChatOpenAI(\n",
        "    temperature=0,\n",
        "    model_name='gpt-3.5-turbo-0125' # default gpt-3.5-turbo\n",
        ")"
      ],
      "metadata": {
        "id": "sR941CKGgJzE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the chain to answer questions\n",
        "qa_chain = RetrievalQA.from_chain_type(llm = model, # default OpenAI()\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)"
      ],
      "metadata": {
        "id": "XVxfF_2aOniK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full example\n",
        "query = \"Tell me something about Interpersonal communication\"\n",
        "llm_response = qa_chain.invoke(query)\n",
        "response_wrap(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsQkbzSgOu2W",
        "outputId": "e1b394fe-cf84-4b4e-8de6-8cd68f4166e0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query: Tell me something about Interpersonal communication\n",
            "\n",
            "result:\n",
            "Interpersonal communication focuses on the exchange of messages between two\n",
            "people in various settings like personal relationships, friendships, and work\n",
            "collaborations. It involves skills associated with effective communication and\n",
            "can help individuals achieve personal and professional goals. It occurs in our\n",
            "daily interactions, such as conversations with significant others, friends, and\n",
            "colleagues. Effective interpersonal communication is essential for building\n",
            "relationships and successful interactions.\n",
            "\n",
            "\n",
            "Sources:\n",
            "/content/Data/Psychology-of-Human-Relations-1695056929._print.pdf\n",
            "/content/Data/Psychology-of-Human-Relations-1695056929._print.pdf\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_response #(type dict) 'source_documents' is the top document and Document is the second top document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KckS3oZfPMv",
        "outputId": "0228f3d6-b262-4dc2-bada-536bc12bac58"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Tell me something about Interpersonal communication',\n",
              " 'result': 'Interpersonal communication focuses on the exchange of messages between two people in various settings like personal relationships, friendships, and work collaborations. It involves skills associated with effective communication and can help individuals achieve personal and professional goals. It occurs in our daily interactions, such as conversations with significant others, friends, and colleagues. Effective interpersonal communication is essential for building relationships and successful interactions.',\n",
              " 'source_documents': [Document(page_content='7.1 Elem ents of Int erpersonal C ommunication\\nLearning Objec tives\\nBy th e en d of this sec tion, y ou will be able t o:\\n•Descr ibe th e diff erences bet ween th e sen der an d receiver of a\\nmessa ge.\\n•Descr ibe th e skills associat ed with eff ective int erpersonal sk ills.\\n•Identif y several diff erent w ays to create bet ter int ercultural\\ninteractions.\\nInterpersonal c ommunication focuses on th e exchange of m essa ges\\nbetween t wo people. Our da ys are full of int erpersonal c ommunication.\\nWhen y ou w ake up , roll o ver, and sa y good m orning to your significant\\nother, you’ve ha d your fir st int erpersonal int eraction of th e da y. You\\nmeet y our best f riend for c offee bef ore work an d discuss th e ins an d\\nouts of c hildr en’s liv es; y ou’re en gaging in int erpersonal\\ncommunication a gain. A t work you c ollabor ate with a c oworker on a\\nprojec t; on ce again, y ou’re en gaging in int erpersonal c ommunication.', metadata={'page': 380, 'source': '/content/Data/Psychology-of-Human-Relations-1695056929._print.pdf'}),\n",
              "  Document(page_content='daily , whic h is int erpersonal c ommunication. Int erpersonal\\ncommunication can h elp us a chieve our per sonal an d pr ofessional\\ngoals. In this c hapt er, you will le arn th e concepts associat ed with\\ninterpersonal c ommunication an d how certain v ariables can h elp y ou\\nachieve your go als.\\nFigur e 7.1aInterpersonal\\ncommunic ation h appens in all of\\nour inf ormalCheckout lin e for\\ngrocery store. Sonn y Doe. CC BY-SA\\n4.0.\\n7.1 Elem ents of Int erpersonal C ommunication |375', metadata={'page': 382, 'source': '/content/Data/Psychology-of-Human-Relations-1695056929._print.pdf'})]}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhQhO-1APTDt",
        "outputId": "1ab39c44-d501-4326-a6d2-f2222e38a242"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('similarity',\n",
              " <langchain_community.vectorstores.chroma.Chroma at 0x7d46d06aad10>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(qa_chain.combine_documents_chain.llm_chain.prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHOzU0HzGTI7",
        "outputId": "d5bbf735-0d22-444b-8820-e0f85f564b52"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Config', 'InputType', 'OutputType', '__abstractmethods__', '__add__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__config__', '__custom_root_type__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__exclude_fields__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_validators__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__include_fields__', '__init__', '__init_subclass__', '__iter__', '__json_encoder__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__orig_bases__', '__parameters__', '__post_root_validators__', '__pre_root_validators__', '__pretty__', '__private_attributes__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__ror__', '__schema_cache__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__try_update_forward_refs__', '__validators__', '__weakref__', '_abatch_with_config', '_abc_impl', '_acall_with_config', '_aformat_prompt_with_error_handling', '_atransform_stream_with_config', '_batch_with_config', '_calculate_keys', '_call_with_config', '_copy_and_set_values', '_decompose_class', '_enforce_dict_if_root', '_format_prompt_with_error_handling', '_get_value', '_init_private_attributes', '_is_protocol', '_iter', '_merge_partial_and_user_variables', '_prompt_type', '_transform_stream_with_config', '_validate_input', 'abatch', 'abatch_as_completed', 'aformat', 'aformat_messages', 'aformat_prompt', 'ainvoke', 'append', 'assign', 'astream', 'astream_events', 'astream_log', 'atransform', 'batch', 'batch_as_completed', 'bind', 'config_schema', 'config_specs', 'configurable_alternatives', 'configurable_fields', 'construct', 'copy', 'dict', 'extend', 'format', 'format_messages', 'format_prompt', 'from_messages', 'from_orm', 'from_role_strings', 'from_strings', 'from_template', 'get_graph', 'get_input_schema', 'get_lc_namespace', 'get_name', 'get_output_schema', 'get_prompts', 'input_schema', 'input_types', 'input_variables', 'invoke', 'is_lc_serializable', 'json', 'lc_attributes', 'lc_id', 'lc_secrets', 'map', 'messages', 'metadata', 'name', 'output_parser', 'output_schema', 'parse_file', 'parse_obj', 'parse_raw', 'partial', 'partial_variables', 'pick', 'pipe', 'pretty_print', 'pretty_repr', 'save', 'schema', 'schema_json', 'stream', 'tags', 'to_json', 'to_json_not_implemented', 'transform', 'update_forward_refs', 'validate', 'validate_input_variables', 'validate_template', 'validate_variable_names', 'with_config', 'with_fallbacks', 'with_listeners', 'with_retry', 'with_types']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8BJ8JyLPac4",
        "outputId": "1888745c-fcf1-4c22-e045-89d6bd44b88d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\")), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To see what was passed to the chain:\n",
        "1. Template text/System prompt\n",
        "2. {context}: two top documents\n",
        "3. Question/query"
      ],
      "metadata": {
        "id": "SyK956fU0nrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = qa_chain.combine_documents_chain.llm_chain.prompt.messages #list len 2\n",
        "template = template[0].prompt.template\n",
        "print(template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dLpgLzzIDgd",
        "outputId": "51c721b9-9d51-478c-8dcb-ff64a92568b9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use the following pieces of context to answer the user's question. \n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "----------------\n",
            "{context}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Creating a db.zip file** that contains all the files and folders within the db directory in the current directory"
      ],
      "metadata": {
        "id": "9igOAmlKM_FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r db.zip ./db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuWol-FZTIXF",
        "outputId": "12579ca2-f4da-49da-dd84-510e80fde846"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: db/ (stored 0%)\n",
            "  adding: db/b94c06c4-0739-4a91-bd66-e38b87641586/ (stored 0%)\n",
            "  adding: db/b94c06c4-0739-4a91-bd66-e38b87641586/length.bin (deflated 94%)\n",
            "  adding: db/b94c06c4-0739-4a91-bd66-e38b87641586/index_metadata.pickle (deflated 42%)\n",
            "  adding: db/b94c06c4-0739-4a91-bd66-e38b87641586/header.bin (deflated 56%)\n",
            "  adding: db/b94c06c4-0739-4a91-bd66-e38b87641586/link_lists.bin (deflated 83%)\n",
            "  adding: db/b94c06c4-0739-4a91-bd66-e38b87641586/data_level0.bin (deflated 17%)\n",
            "  adding: db/chroma.sqlite3 (deflated 38%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deleting db folder/collection from colab"
      ],
      "metadata": {
        "id": "i94jiz9LNjlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing files and its directory (db/)\n",
        "!rm -rf db/"
      ],
      "metadata": {
        "id": "-JB3Klj5TOFW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To start again from zip db:\n",
        "\n",
        "\n",
        "\n",
        "1.   Restart runtime in Colab\n",
        "2.   Get openAI key and make all imports from beginning of the notebook. Plus execute response_wrap() function\n",
        "\n"
      ],
      "metadata": {
        "id": "SZzc8-TLPdx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip db.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp2c4fHSTT3m",
        "outputId": "6c5e2477-2b9b-409c-9099-df9f0c2ba68f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  db.zip\n",
            "   creating: db/\n",
            "   creating: db/b94c06c4-0739-4a91-bd66-e38b87641586/\n",
            "  inflating: db/b94c06c4-0739-4a91-bd66-e38b87641586/length.bin  \n",
            "  inflating: db/b94c06c4-0739-4a91-bd66-e38b87641586/index_metadata.pickle  \n",
            "  inflating: db/b94c06c4-0739-4a91-bd66-e38b87641586/header.bin  \n",
            "  inflating: db/b94c06c4-0739-4a91-bd66-e38b87641586/link_lists.bin  \n",
            "  inflating: db/b94c06c4-0739-4a91-bd66-e38b87641586/data_level0.bin  \n",
            "  inflating: db/chroma.sqlite3       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = 'db'\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb2 = Chroma(persist_directory=persist_directory,\n",
        "                  embedding_function=embedding,\n",
        "                   )\n",
        "\n",
        "retriever = vectordb2.as_retriever(search_kwargs={\"k\": 2})"
      ],
      "metadata": {
        "id": "DWLV5OeRTjNY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the turbo LLM\n",
        "model = ChatOpenAI(\n",
        "    temperature=0,\n",
        "    model_name='gpt-3.5-turbo-0125' # default gpt-3.5-turbo\n",
        ")"
      ],
      "metadata": {
        "id": "gdG87E4Vj-8q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the chain to answer questions\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=model,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)"
      ],
      "metadata": {
        "id": "q4-Q0tz6kGTT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full example\n",
        "query = \"Tell me something about Interpersonal communication\"\n",
        "llm_response = qa_chain.invoke(query)\n",
        "response_wrap(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hipGJTEwkQ56",
        "outputId": "19ef34fc-aae0-4810-f6cd-5c835dfee387"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query: Tell me something about Interpersonal communication\n",
            "\n",
            "result:\n",
            "Interpersonal communication focuses on the exchange of messages between two\n",
            "people in various settings like at home, with friends, or at work. It involves\n",
            "interactions such as saying good morning to a significant other, discussing life\n",
            "events with a friend, or collaborating with a coworker on a project. Effective\n",
            "interpersonal communication skills are essential for achieving personal and\n",
            "professional goals. It involves understanding the differences between the sender\n",
            "and receiver of a message, developing effective interpersonal skills, and\n",
            "creating better interactions, including intercultural interactions.\n",
            "\n",
            "\n",
            "Sources:\n",
            "/content/Data/Psychology-of-Human-Relations-1695056929._print.pdf\n",
            "/content/Data/Psychology-of-Human-Relations-1695056929._print.pdf\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is genesis of Abnormal Behavior?\"\n",
        "llm_response = qa_chain.invoke(query)\n",
        "response_wrap(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeI0KjL5qGIw",
        "outputId": "6ddb2a3b-6bf3-46c5-fe92-be1c66b6a538"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query: What is genesis of Abnormal Behavior?\n",
            "\n",
            "result:\n",
            "The genesis of abnormal behavior can be attributed to a combination of factors\n",
            "such as personal distress, psychological dysfunction, deviance from social\n",
            "norms, dangerousness to self and others, and costliness to society. Abnormal\n",
            "behavior is not just a result of one specific cause but rather a complex\n",
            "interplay of various factors that contribute to maladaptive behavior.\n",
            "\n",
            "\n",
            "Sources:\n",
            "/content/Data/Fundamentals-of-Psychological-Disorders.pdf\n",
            "/content/Data/Fundamentals-of-Psychological-Disorders.pdf\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Powiedz mi cos o emocjach w psychologii\"\n",
        "llm_response = qa_chain.invoke(query)\n",
        "response_wrap(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp_mwG5KVHAp",
        "outputId": "cff25ccc-0ea8-47c7-8826-eeb9fd34849b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query: Powiedz mi cos o emocjach w psychologii\n",
            "\n",
            "result:\n",
            "Emocje w psychologii są złożonymi reakcjami organizmu na bodźce zewnętrzne lub\n",
            "wewnętrzne. Badania nad emocjami obejmują różnorodne aspekty, takie jak\n",
            "wyrażanie emocji, rozpoznawanie emocji u innych, wpływ emocji na zachowanie i\n",
            "zdrowie psychiczne. Emocje odgrywają istotną rolę w relacjach międzyludzkich i w\n",
            "procesie podejmowania decyzji.\n",
            "\n",
            "\n",
            "Sources:\n",
            "/content/Data/Psychology-of-Human-Relations-1695056929._print.pdf\n",
            "/content/Data/Psychology-of-Human-Relations-1695056929._print.pdf\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template) # System prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brLxIRekkdav",
        "outputId": "ede5b997-bfda-4d8a-ba2c-7426fa6e3062"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use the following pieces of context to answer the user's question. \n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "----------------\n",
            "{context}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[1].prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EvVTvSLkgYT",
        "outputId": "13e66f7a-a339-4928-aa7b-4997bca55d92"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{question}\n"
          ]
        }
      ]
    }
  ]
}